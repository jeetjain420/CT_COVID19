{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "from PIL import ImageFile\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random \n",
    "from shutil import copyfile\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensor\n",
    "from catalyst.data import Augmentor\n",
    "import torchxrayvision as xrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensor\n",
    "from catalyst.data import Augmentor\n",
    "from skimage.io import imread, imsave\n",
    "import skimage\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: efficientnet-pytorch in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (0.6.3)\n",
      "Requirement already satisfied, skipping upgrade: torch in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from efficientnet-pytorch) (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "get_ipython().system('pip install --upgrade efficientnet-pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop((224),scale=(0.5,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "val_transformer = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425\n",
      "118\n",
      "203\n"
     ]
    }
   ],
   "source": [
    "batchsize=10\n",
    "def read_txt(txt_path):\n",
    "    with open(txt_path) as f:\n",
    "        lines = f.readlines()\n",
    "    txt_data = [line.strip() for line in lines]\n",
    "    return txt_data\n",
    "\n",
    "class CovidCTDataset(Dataset):\n",
    "    def __init__(self, root_dir, txt_COVID, txt_NonCOVID, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            txt_path (string): Path to the txt file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        File structure:\n",
    "        - root_dir\n",
    "            - CT_COVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "            - CT_NonCOVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.txt_path = [txt_COVID,txt_NonCOVID]\n",
    "        self.classes = ['CT_COVID', 'CT_NonCOVID']\n",
    "        self.num_cls = len(self.classes)\n",
    "        self.img_list = []\n",
    "        for c in range(self.num_cls):\n",
    "            cls_list = [[os.path.join(self.root_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]\n",
    "            self.img_list += cls_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.img_list[idx][0]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample = {'img': image,\n",
    "                  'label': int(self.img_list[idx][1])}\n",
    "        return sample\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    trainset = CovidCTDataset(root_dir=r'C:\\Users\\acer pc\\OneDrive\\Desktop\\COVID-CT-master\\Images-processed',\n",
    "                              txt_COVID=r'C:\\Users\\acer pc\\OneDrive\\Desktop\\COVID-CT-master\\Data-split\\COVID\\trainCT_COVID.txt',\n",
    "                              txt_NonCOVID=r'C:\\Users\\acer pc\\OneDrive\\Desktop\\COVID-CT-master\\Data-split\\NonCOVID\\trainCT_NonCovid.txt',\n",
    "                              transform= train_transformer)\n",
    "    valset = CovidCTDataset(root_dir=r'C:\\Users\\acer pc\\OneDrive\\Desktop\\COVID-CT-master\\Images-processed',\n",
    "                              txt_COVID=r'C:\\Users\\acer pc\\OneDrive\\Desktop\\COVID-CT-master\\Data-split\\COVID\\valCT_COVID.txt',\n",
    "                              txt_NonCOVID=r'C:\\Users\\acer pc\\OneDrive\\Desktop\\COVID-CT-master\\Data-split\\NonCOVID\\valCT_NonCOVID.txt',\n",
    "                              transform= val_transformer)\n",
    "    testset = CovidCTDataset(root_dir=r'C:\\Users\\acer pc\\OneDrive\\Desktop\\COVID-CT-master\\Images-processed',\n",
    "                              txt_COVID=r'C:\\Users\\acer pc\\OneDrive\\Desktop\\COVID-CT-master\\Data-split\\COVID\\testCT_COVID.txt',\n",
    "                              txt_NonCOVID=r'C:\\Users\\acer pc\\OneDrive\\Desktop\\COVID-CT-master\\Data-split\\NonCOVID\\testCT_NonCOVID.txt',\n",
    "                              transform= val_transformer)\n",
    "    print(trainset.__len__())\n",
    "    print(valset.__len__())\n",
    "    print(testset.__len__())\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=batchsize, drop_last=False, shuffle=True)\n",
    "    val_loader = DataLoader(valset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "    test_loader = DataLoader(testset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = None\n",
    "device = 'cuda'\n",
    "def train(optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    for batch_index, batch_samples in enumerate(train_loader):\n",
    "        \n",
    "        # move data to device\n",
    "        data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "#        data = data[:, 0, :, :]\n",
    "#        data = data[:, None, :, :]\n",
    "#         data, targets_a, targets_b, lam = mixup_data(data, target.long(), alpha, use_cuda=True)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        criteria = nn.CrossEntropyLoss()\n",
    "        loss = criteria(output, target.long())\n",
    "#         loss = mixup_criterion(criteria, output, targets_a, targets_b, lam)\n",
    "        train_loss += criteria(output, target.long())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        train_correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "    \n",
    "        # Display progress and write to tensorboard\n",
    "        if batch_index % bs == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(\n",
    "                epoch, batch_index, len(train_loader),\n",
    "                100.0 * batch_index / len(train_loader), loss.item()/ bs))\n",
    "    \n",
    "    print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "        100.0 * train_correct / len(train_loader.dataset)))\n",
    "    #f = open('model_result/{}.txt'.format(modelname), 'a+')\n",
    "    #f.write('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        #rain_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "        #00.0 * train_correct / len(train_loader.dataset)))\n",
    "    #.write('\\n')\n",
    "    #.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        # Predict\n",
    "        for batch_index, batch_samples in enumerate(val_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "#            data = data[:, 0, :, :]\n",
    "#            data = data[:, None, :, :]\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criteria(output, target.long())\n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "#             print('target',target.long()[:, 2].view_as(pred))\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "            \n",
    "#             print(output[:,1].cpu().numpy())\n",
    "#             print((output[:,1]+output[:,0]).cpu().numpy())\n",
    "#             predcpu=(output[:,1].cpu().numpy())/((output[:,1]+output[:,0]).cpu().numpy())\n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "           \n",
    "          \n",
    "    return targetlist, scorelist, predlist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        # Predict\n",
    "        for batch_index, batch_samples in enumerate(test_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "#            data = data[:, 0, :, :]\n",
    "#            data = data[:, None, :, :]\n",
    "#             print(target)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criteria(output, target.long())\n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "#             print('target',target.long()[:, 2].view_as(pred))\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "#             TP += ((pred == 1) & (target.long()[:, 2].view_as(pred).data == 1)).cpu().sum()\n",
    "#             TN += ((pred == 0) & (target.long()[:, 2].view_as(pred) == 0)).cpu().sum()\n",
    "# #             # FN    predict 0 label 1\n",
    "#             FN += ((pred == 0) & (target.long()[:, 2].view_as(pred) == 1)).cpu().sum()\n",
    "# #             # FP    predict 1 label 0\n",
    "#             FP += ((pred == 1) & (target.long()[:, 2].view_as(pred) == 0)).cpu().sum()\n",
    "#             print(TP,TN,FN,FP)\n",
    "            \n",
    "            \n",
    "#             print(output[:,1].cpu().numpy())\n",
    "#             print((output[:,1]+output[:,0]).cpu().numpy())\n",
    "#             predcpu=(output[:,1].cpu().numpy())/((output[:,1]+output[:,0]).cpu().numpy())\n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "           \n",
    "    return targetlist, scorelist, predlist\n",
    "    \n",
    "    # Write to tensorboard\n",
    "#     writer.add_scalar('Test Accuracy', 100.0 * correct / len(test_loader.dataset), epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNetModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Pass in parsed HyperOptArgumentParser to the model\n",
    "        :param hparams:\n",
    "        \"\"\"\n",
    "        super(DenseNetModel, self).__init__()\n",
    "\n",
    "        self.dense_net = xrv.models.DenseNet(num_classes=2)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.dense_net(x)\n",
    "        return logits\n",
    "    \n",
    "model = DenseNetModel().cuda()\n",
    "modelname = 'DenseNet_medical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__() # b, 3, 32, 32\n",
    "        layer1 = torch.nn.Sequential() \n",
    "        layer1.add_module('conv1', torch.nn.Conv2d(3, 32, 3, 1, padding=1))\n",
    " \n",
    "        #b, 32, 32, 32\n",
    "        layer1.add_module('relu1', torch.nn.ReLU(True)) \n",
    "        layer1.add_module('pool1', torch.nn.MaxPool2d(2, 2)) # b, 32, 16, 16 //池化为16*16\n",
    "        self.layer1 = layer1\n",
    "        layer4 = torch.nn.Sequential()\n",
    "        layer4.add_module('fc1', torch.nn.Linear(401408, 2))       \n",
    "        self.layer4 = layer4\n",
    " \n",
    "    def forward(self, x):\n",
    "        conv1 = self.layer1(x)\n",
    "        fc_input = conv1.view(conv1.size(0), -1)\n",
    "        fc_out = self.layer4(fc_input)\n",
    " \n",
    "model = SimpleCNN().cuda()\n",
    "modelname = 'SimpleCNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to C:\\Users\\acer pc/.cache\\torch\\checkpoints\\resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616307587d5146da9160362a537add03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet18(pretrained=True).cuda()\n",
    "modelname = 'ResNet18'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\acer pc/.cache\\torch\\checkpoints\\densenet121-a639ec97.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f09b7a01624a52b26d02d15b43ca79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32342954.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "model = models.densenet121(pretrained=True).cuda()\n",
    "modelname = 'Dense121'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to C:\\Users\\acer pc/.cache\\torch\\checkpoints\\densenet169-b2777c0a.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc9af634f0e4f00b374cff50965debd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57365526.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "model = models.densenet169(pretrained=True).cuda()\n",
    "modelname = 'Dense169'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to C:\\Users\\acer pc/.cache\\torch\\checkpoints\\resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea42c946074402ab8157464e2afa2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet50(pretrained=True).cuda()\n",
    "modelname = 'ResNet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\acer pc/.cache\\torch\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655c4add88f3457caa05f63b0e48fb45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "model = models.vgg16(pretrained=True)\n",
    "model = model.cuda()\n",
    "modelname = 'vgg16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to C:\\Users\\acer pc/.cache\\torch\\checkpoints\\efficientnet-b0-355c32eb.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158ed94417c545509fbbd48639b58b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21388428.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=2)\n",
    "model = model.cuda()\n",
    "modelname = 'efficientNet-b0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/43 (0%)]\tTrain Loss: 0.048089\n",
      "Train Epoch: 1 [10/43 (23%)]\tTrain Loss: 0.057794\n",
      "Train Epoch: 1 [20/43 (47%)]\tTrain Loss: 0.034929\n",
      "Train Epoch: 1 [30/43 (70%)]\tTrain Loss: 0.040732\n",
      "Train Epoch: 1 [40/43 (93%)]\tTrain Loss: 0.035544\n",
      "\n",
      "Train set: Average loss: 0.0489, Accuracy: 336/425 (79%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.78604603 0.53037846 0.33530504 0.61811274 0.48690695 0.57132941\n",
      " 0.44371775 0.67607331 0.4971979  0.32758746 0.25446317 0.23043379\n",
      " 0.57080883 0.31788579 0.5135749  0.33965069 0.34368911 0.40040055\n",
      " 0.40640482 0.62780571 0.69713891 0.63670009 0.68504941 0.70399261\n",
      " 0.57004929 0.61366689 0.66200328 0.71490037 0.59412962 0.40924478\n",
      " 0.70558572 0.84742659 0.78033507 0.39587557 0.24251172 0.38757676\n",
      " 0.52468747 0.79633474 0.69629848 0.48509872 0.52960819 0.44948843\n",
      " 0.68580198 0.57414258 0.74829721 0.63055843 0.70573252 0.78759795\n",
      " 0.77736038 0.3380208  0.73231637 0.33035368 0.37799415 0.25637493\n",
      " 0.37401152 0.43395367 0.62195277 0.31526059 0.33820236 0.54035765\n",
      " 0.82724428 0.69092888 0.92653632 0.77942163 0.68149912 0.6257754\n",
      " 0.7550481  0.97112066 0.80209655 0.66663671 0.56204587 0.60707045\n",
      " 0.92972249 0.74333113 0.9051457  0.85633403 0.93314356 0.7833848\n",
      " 0.89472026 0.92604136 0.91916573 0.92570996 0.89447093 0.63688624\n",
      " 0.4918797  0.69169235 0.77012515 0.7546804  0.4896934  0.71163607\n",
      " 0.61539245 0.4057371  0.50143427 0.58015168 0.39789584 0.58600676\n",
      " 0.59310126 0.72786695 0.56583661 0.76024419 0.3744995  0.86564112\n",
      " 0.91239381 0.46389094 0.59545803 0.4608354  0.51948935 0.36938146\n",
      " 0.59043586 0.40588805 0.54854017 0.29123455 0.55347335 0.75873142\n",
      " 0.70112085 0.89068729 0.97488302 0.92599511]\n",
      "predict [1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 2 [0/43 (0%)]\tTrain Loss: 0.047746\n",
      "Train Epoch: 2 [10/43 (23%)]\tTrain Loss: 0.035727\n",
      "Train Epoch: 2 [20/43 (47%)]\tTrain Loss: 0.034587\n",
      "Train Epoch: 2 [30/43 (70%)]\tTrain Loss: 0.058399\n",
      "Train Epoch: 2 [40/43 (93%)]\tTrain Loss: 0.025968\n",
      "\n",
      "Train set: Average loss: 0.0396, Accuracy: 356/425 (84%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.63496619 0.41509324 0.26927373 0.35967165 0.18769717 0.34929287\n",
      " 0.34533167 0.46368825 0.35305229 0.23215215 0.11326825 0.1668663\n",
      " 0.53731227 0.22455515 0.31747019 0.15352346 0.15825655 0.37253219\n",
      " 0.25921783 0.53798795 0.67900252 0.67316097 0.66251087 0.73527598\n",
      " 0.6020745  0.53103024 0.57038051 0.6546967  0.29257554 0.17840144\n",
      " 0.46238157 0.72204149 0.69228297 0.13549045 0.06187424 0.14660718\n",
      " 0.29191405 0.81189364 0.57071912 0.34136787 0.32179579 0.14023693\n",
      " 0.51967198 0.37014329 0.64854252 0.32397172 0.60079747 0.75715733\n",
      " 0.65661514 0.26673204 0.56941885 0.11222485 0.22073908 0.05906853\n",
      " 0.35350561 0.19143368 0.70889401 0.10241862 0.28815845 0.28576246\n",
      " 0.88471794 0.64226127 0.96005642 0.79766607 0.53047574 0.43650293\n",
      " 0.46501556 0.99387014 0.808595   0.62873518 0.38544542 0.42439869\n",
      " 0.87413883 0.59440112 0.79170561 0.85555255 0.9402234  0.75343138\n",
      " 0.90215492 0.95522171 0.95617974 0.9512316  0.96688318 0.56393421\n",
      " 0.43890116 0.76699162 0.70841956 0.59589052 0.29207069 0.63394463\n",
      " 0.52993023 0.26016212 0.29241467 0.68049753 0.34291118 0.43433309\n",
      " 0.35056785 0.86209893 0.6749416  0.84233129 0.40085402 0.94607943\n",
      " 0.83579516 0.34411323 0.51422578 0.39208743 0.49267265 0.26455179\n",
      " 0.46866995 0.17228653 0.44156662 0.29836494 0.66670787 0.73968691\n",
      " 0.42004684 0.84032178 0.98977214 0.97585195]\n",
      "predict [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 3 [0/43 (0%)]\tTrain Loss: 0.024546\n",
      "Train Epoch: 3 [10/43 (23%)]\tTrain Loss: 0.077352\n",
      "Train Epoch: 3 [20/43 (47%)]\tTrain Loss: 0.023879\n",
      "Train Epoch: 3 [30/43 (70%)]\tTrain Loss: 0.038360\n",
      "Train Epoch: 3 [40/43 (93%)]\tTrain Loss: 0.023487\n",
      "\n",
      "Train set: Average loss: 0.0316, Accuracy: 371/425 (87%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.33305648 0.31099778 0.17434254 0.23872235 0.0908842  0.14112563\n",
      " 0.26867732 0.4246152  0.19789428 0.09077837 0.20735547 0.04671027\n",
      " 0.24815844 0.13990963 0.24602012 0.07630754 0.07552434 0.18945771\n",
      " 0.14428622 0.47779831 0.55117416 0.58527833 0.53815031 0.67862976\n",
      " 0.55124688 0.48771098 0.48066679 0.71982801 0.21140464 0.12307294\n",
      " 0.5129118  0.87346095 0.72516775 0.03382149 0.02666469 0.04973878\n",
      " 0.12561758 0.78274763 0.4801766  0.34980929 0.24754773 0.06998821\n",
      " 0.38016662 0.27700162 0.78694636 0.09532376 0.54214978 0.73559731\n",
      " 0.65205508 0.06715319 0.55377334 0.02798936 0.07405651 0.01685574\n",
      " 0.10214511 0.0754444  0.70733672 0.01726834 0.0790178  0.16194469\n",
      " 0.89384317 0.27812737 0.67179352 0.58436102 0.65282786 0.56452698\n",
      " 0.68788701 0.9986077  0.87274867 0.73916048 0.27883074 0.31216326\n",
      " 0.92793864 0.67346436 0.84267509 0.89864516 0.9127695  0.6894381\n",
      " 0.93888038 0.99286205 0.99423367 0.99640346 0.99878889 0.28116712\n",
      " 0.18309249 0.69866097 0.70240027 0.62448543 0.21519381 0.52305371\n",
      " 0.54173017 0.22738755 0.20862547 0.65850127 0.22865649 0.2943604\n",
      " 0.17171796 0.86790913 0.66372502 0.87779433 0.29326826 0.97126627\n",
      " 0.7092241  0.23459679 0.41023698 0.26813567 0.53677678 0.1921394\n",
      " 0.29804385 0.06043076 0.31610608 0.19136879 0.62895405 0.77696609\n",
      " 0.227643   0.83299267 0.98935473 0.97738123]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 4 [0/43 (0%)]\tTrain Loss: 0.021641\n",
      "Train Epoch: 4 [10/43 (23%)]\tTrain Loss: 0.027896\n",
      "Train Epoch: 4 [20/43 (47%)]\tTrain Loss: 0.018358\n",
      "Train Epoch: 4 [30/43 (70%)]\tTrain Loss: 0.016621\n",
      "Train Epoch: 4 [40/43 (93%)]\tTrain Loss: 0.025416\n",
      "\n",
      "Train set: Average loss: 0.0225, Accuracy: 391/425 (92%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.16730027 0.24385369 0.18241802 0.12834907 0.03076083 0.0726207\n",
      " 0.22823022 0.16783403 0.16855569 0.0574154  0.33643627 0.02777305\n",
      " 0.23223458 0.11503524 0.13808228 0.02647372 0.0381283  0.10395701\n",
      " 0.09686494 0.58328372 0.67402703 0.68047476 0.68640536 0.82071948\n",
      " 0.64604831 0.68891537 0.60883468 0.73279369 0.1645631  0.07310182\n",
      " 0.20060715 0.44997135 0.31395876 0.01479961 0.00851114 0.02966463\n",
      " 0.04927123 0.38146284 0.14913635 0.2029247  0.09796906 0.01696505\n",
      " 0.129721   0.16363302 0.6992721  0.01362899 0.16776615 0.299018\n",
      " 0.30246219 0.04738132 0.18019684 0.00422288 0.04916158 0.00207502\n",
      " 0.12165353 0.0447563  0.89166552 0.00396155 0.04627239 0.05113157\n",
      " 0.95653421 0.61355156 0.9651528  0.75392199 0.34770274 0.27216566\n",
      " 0.18099685 0.99892104 0.81531113 0.54149234 0.08842137 0.11518364\n",
      " 0.49110532 0.33837932 0.40374976 0.91647005 0.92781967 0.68493533\n",
      " 0.87342209 0.94722754 0.97264636 0.9704771  0.99823028 0.28510144\n",
      " 0.14045045 0.65834755 0.69746953 0.56384325 0.186243   0.47490934\n",
      " 0.65662998 0.06864356 0.03664093 0.88851523 0.32902476 0.52930993\n",
      " 0.19591717 0.96670157 0.94138795 0.87959391 0.47633201 0.93366474\n",
      " 0.68034756 0.1432199  0.2809405  0.24829328 0.51866269 0.13789344\n",
      " 0.22752658 0.04157915 0.29690361 0.144385   0.76325446 0.91212875\n",
      " 0.11851827 0.7601245  0.99856406 0.99300379]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [0/43 (0%)]\tTrain Loss: 0.022524\n",
      "Train Epoch: 5 [10/43 (23%)]\tTrain Loss: 0.006351\n",
      "Train Epoch: 5 [20/43 (47%)]\tTrain Loss: 0.011227\n",
      "Train Epoch: 5 [30/43 (70%)]\tTrain Loss: 0.015963\n",
      "Train Epoch: 5 [40/43 (93%)]\tTrain Loss: 0.008147\n",
      "\n",
      "Train set: Average loss: 0.0214, Accuracy: 388/425 (91%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.10373373 0.23276098 0.22860242 0.07893756 0.01041649 0.03360765\n",
      " 0.20512386 0.2007744  0.12002386 0.3038913  0.45930412 0.04579239\n",
      " 0.30641842 0.09576638 0.10175588 0.03934499 0.03019305 0.05801589\n",
      " 0.03523413 0.46075484 0.52500093 0.58990902 0.49277705 0.80810159\n",
      " 0.61670142 0.55319458 0.5658474  0.78730673 0.14440092 0.04228348\n",
      " 0.23123771 0.44445252 0.34321478 0.00437953 0.00362233 0.01855845\n",
      " 0.01670148 0.38187274 0.11373528 0.1275039  0.04064316 0.00581231\n",
      " 0.07366224 0.09282269 0.68141627 0.01590504 0.19951852 0.2238594\n",
      " 0.31329975 0.03106676 0.14374372 0.00350527 0.05425882 0.00140073\n",
      " 0.18686096 0.11140023 0.92839843 0.0054137  0.03625566 0.0428381\n",
      " 0.92745    0.73117286 0.95984823 0.78443521 0.40359676 0.46073654\n",
      " 0.37431651 0.99943179 0.87519222 0.76959974 0.04733883 0.07131023\n",
      " 0.73518825 0.47780931 0.62549692 0.91186935 0.91418052 0.64872426\n",
      " 0.90468377 0.95963871 0.98990661 0.96963692 0.99102354 0.23757637\n",
      " 0.07157449 0.68218637 0.56440765 0.57594371 0.13090757 0.59744459\n",
      " 0.7230947  0.05833881 0.02922774 0.9450115  0.31212956 0.48191974\n",
      " 0.23255251 0.96204489 0.90576488 0.9567309  0.34877715 0.86435795\n",
      " 0.47200677 0.10966102 0.10913961 0.20197897 0.49929151 0.13164613\n",
      " 0.27671897 0.02997387 0.37453642 0.0954963  0.7868914  0.97284716\n",
      " 0.03907217 0.68900383 0.9979862  0.99577242]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 6 [0/43 (0%)]\tTrain Loss: 0.009390\n",
      "Train Epoch: 6 [10/43 (23%)]\tTrain Loss: 0.007451\n",
      "Train Epoch: 6 [20/43 (47%)]\tTrain Loss: 0.006061\n",
      "Train Epoch: 6 [30/43 (70%)]\tTrain Loss: 0.007105\n",
      "Train Epoch: 6 [40/43 (93%)]\tTrain Loss: 0.058664\n",
      "\n",
      "Train set: Average loss: 0.0213, Accuracy: 387/425 (91%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.13521214e-02 1.00456685e-01 8.42817724e-02 6.26920313e-02\n",
      " 1.37764076e-03 1.00625269e-02 8.33870769e-02 1.67962193e-01\n",
      " 5.47351278e-02 3.14808339e-01 6.26145959e-01 6.66705593e-02\n",
      " 5.27143180e-01 6.58964589e-02 7.29907006e-02 1.44916987e-02\n",
      " 7.63470586e-03 2.28228904e-02 3.92590696e-03 1.28917456e-01\n",
      " 2.13079318e-01 6.23933733e-01 1.07256442e-01 7.34669745e-01\n",
      " 2.82535404e-01 1.34688482e-01 8.10366869e-02 3.25092614e-01\n",
      " 2.85099670e-02 1.99432690e-02 4.62883860e-02 3.16416174e-01\n",
      " 2.06516489e-01 6.80141617e-04 1.39574078e-03 8.08430184e-03\n",
      " 3.87358759e-03 5.43671846e-02 6.73158541e-02 1.60586778e-02\n",
      " 5.74746914e-03 1.51152210e-03 5.61340675e-02 2.13374346e-02\n",
      " 7.18615294e-01 2.02529021e-02 1.82645783e-01 1.13458328e-01\n",
      " 1.43625453e-01 5.90025336e-02 1.01239987e-01 1.52047013e-03\n",
      " 1.00839064e-02 6.79399818e-04 3.44557874e-02 4.87715192e-02\n",
      " 7.32163727e-01 2.10373616e-03 3.33241336e-02 1.01143960e-02\n",
      " 9.20368433e-01 8.23192239e-01 9.88358974e-01 8.25745165e-01\n",
      " 3.57370734e-01 5.18937647e-01 1.70977041e-01 9.99911904e-01\n",
      " 9.57105875e-01 7.88576901e-01 1.76303294e-02 3.08682434e-02\n",
      " 4.17353421e-01 3.48122388e-01 5.39185166e-01 9.04986739e-01\n",
      " 9.54118490e-01 5.99034488e-01 9.33656037e-01 8.68271053e-01\n",
      " 9.64676976e-01 8.70299041e-01 9.90936577e-01 1.76161066e-01\n",
      " 5.80881909e-02 4.55561817e-01 4.86313611e-01 1.80263907e-01\n",
      " 3.77344675e-02 2.46267527e-01 7.36549139e-01 2.15682238e-02\n",
      " 1.09536545e-02 8.85504961e-01 1.30611122e-01 1.91250816e-01\n",
      " 1.46661177e-01 5.36248446e-01 3.69629264e-01 9.23717022e-01\n",
      " 9.92797464e-02 8.11250150e-01 2.51634151e-01 2.51429416e-02\n",
      " 1.19056795e-02 4.09074217e-01 2.92696923e-01 2.60436237e-02\n",
      " 3.51949334e-02 7.10250903e-03 4.12587933e-02 2.28117872e-02\n",
      " 3.50921869e-01 8.25192869e-01 1.89799536e-02 4.55496430e-01\n",
      " 9.94155288e-01 9.84830141e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 7 [0/43 (0%)]\tTrain Loss: 0.019131\n",
      "Train Epoch: 7 [10/43 (23%)]\tTrain Loss: 0.006852\n",
      "Train Epoch: 7 [20/43 (47%)]\tTrain Loss: 0.020612\n",
      "Train Epoch: 7 [30/43 (70%)]\tTrain Loss: 0.017293\n",
      "Train Epoch: 7 [40/43 (93%)]\tTrain Loss: 0.062574\n",
      "\n",
      "Train set: Average loss: 0.0213, Accuracy: 381/425 (90%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.72668395e-02 7.93890283e-02 9.61252823e-02 4.28510159e-02\n",
      " 8.19825043e-04 5.96953416e-03 7.99676105e-02 8.59335959e-02\n",
      " 4.04428430e-02 3.34967881e-01 6.38130665e-01 4.87953946e-02\n",
      " 6.21881783e-01 1.65887754e-02 1.74980760e-02 8.02293047e-03\n",
      " 8.10919236e-03 4.23221998e-02 3.52995191e-03 1.79617405e-01\n",
      " 2.24993035e-01 7.05128968e-01 6.19346760e-02 8.68695021e-01\n",
      " 5.52528739e-01 5.99161126e-02 1.24113537e-01 2.37751245e-01\n",
      " 1.10292146e-02 1.07141417e-02 1.08780172e-02 6.97181746e-02\n",
      " 5.59134223e-02 5.74139587e-04 9.94242379e-04 4.98191034e-03\n",
      " 2.56562303e-03 1.72969662e-02 6.77864179e-02 7.69941323e-03\n",
      " 5.08132158e-03 1.00871059e-03 2.70537231e-02 9.01912805e-03\n",
      " 2.74088562e-01 4.20284458e-03 3.93132642e-02 3.74427624e-02\n",
      " 7.03742877e-02 5.44905849e-02 6.56004921e-02 4.50999039e-04\n",
      " 7.07107317e-03 2.59801251e-04 3.81231494e-02 1.67585574e-02\n",
      " 7.20150173e-01 1.05854531e-03 2.32478399e-02 1.70361600e-03\n",
      " 9.48179126e-01 9.09262121e-01 9.91612196e-01 9.14364755e-01\n",
      " 9.69074145e-02 2.28514761e-01 2.09361501e-02 9.99583185e-01\n",
      " 9.25890923e-01 7.49736965e-01 1.29495859e-02 1.92246605e-02\n",
      " 3.54421675e-01 1.28385976e-01 2.19727695e-01 6.98940933e-01\n",
      " 9.16319072e-01 3.46897930e-01 7.39804506e-01 8.31742585e-01\n",
      " 7.33203471e-01 5.16850591e-01 9.66278076e-01 2.10257143e-01\n",
      " 5.31061478e-02 6.64985061e-01 5.05756378e-01 2.15909824e-01\n",
      " 1.57229714e-02 3.74757767e-01 7.14114785e-01 5.64955967e-03\n",
      " 3.05852038e-03 8.66065919e-01 1.73976123e-01 1.64245546e-01\n",
      " 9.30752531e-02 8.95926952e-01 5.69409668e-01 9.24332917e-01\n",
      " 2.79498070e-01 8.46661747e-01 5.52784801e-01 2.20489148e-02\n",
      " 7.02438969e-03 3.52601260e-01 3.55404586e-01 3.91890667e-02\n",
      " 9.98899788e-02 1.21038407e-02 1.16272375e-01 4.72153164e-02\n",
      " 4.90078896e-01 9.61677492e-01 2.41616871e-02 3.98448974e-01\n",
      " 9.97887909e-01 9.98087585e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 8 [0/43 (0%)]\tTrain Loss: 0.009028\n",
      "Train Epoch: 8 [10/43 (23%)]\tTrain Loss: 0.006427\n",
      "Train Epoch: 8 [20/43 (47%)]\tTrain Loss: 0.017482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [30/43 (70%)]\tTrain Loss: 0.017027\n",
      "Train Epoch: 8 [40/43 (93%)]\tTrain Loss: 0.005695\n",
      "\n",
      "Train set: Average loss: 0.0130, Accuracy: 411/425 (97%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.05727278e-02 7.97724649e-02 5.78629784e-02 2.39943787e-02\n",
      " 4.08158114e-04 2.25212565e-03 6.53711334e-02 5.21901883e-02\n",
      " 1.85942762e-02 1.05548516e-01 5.01042366e-01 1.45584522e-02\n",
      " 3.10473621e-01 2.51083309e-03 6.02150382e-03 1.10879249e-03\n",
      " 6.84218539e-04 7.48416502e-03 2.60520400e-03 5.94175905e-02\n",
      " 6.19795024e-02 5.38981795e-01 6.40420243e-02 8.64069879e-01\n",
      " 3.64378273e-01 4.07957919e-02 1.37533233e-01 2.81698585e-01\n",
      " 1.23970816e-02 4.26705740e-03 1.70004107e-02 3.31338525e-01\n",
      " 1.24864198e-01 1.73908396e-04 4.56182839e-04 1.10569864e-03\n",
      " 4.91982617e-04 6.84240647e-03 2.36989129e-02 2.29342096e-03\n",
      " 2.53388146e-03 5.04482829e-04 1.02820005e-02 5.31571824e-03\n",
      " 6.00369811e-01 4.79965173e-02 1.25501305e-01 1.60244957e-01\n",
      " 4.07652646e-01 4.43140157e-02 7.19933867e-01 2.72472651e-04\n",
      " 4.06936463e-03 3.48199712e-04 1.17597412e-02 8.85332841e-03\n",
      " 5.66996038e-01 6.02120184e-04 1.21137258e-02 7.57403090e-04\n",
      " 9.96791661e-01 9.77291822e-01 9.98984396e-01 9.95060146e-01\n",
      " 2.06163585e-01 5.39094090e-01 6.04929477e-02 9.99997735e-01\n",
      " 9.82042372e-01 9.38871026e-01 3.89651135e-02 4.81273308e-02\n",
      " 9.04222012e-01 3.46874863e-01 4.42571580e-01 9.59676504e-01\n",
      " 9.86059010e-01 6.44774556e-01 9.87661600e-01 9.96704280e-01\n",
      " 9.97669876e-01 9.80530381e-01 9.99415398e-01 4.04269159e-01\n",
      " 2.73748133e-02 9.82604802e-01 9.45066869e-01 6.78024828e-01\n",
      " 7.58203678e-03 1.35742888e-01 8.98139060e-01 6.62910659e-03\n",
      " 3.02760745e-03 9.18800294e-01 1.22030407e-01 1.41217351e-01\n",
      " 1.96843907e-01 9.43283617e-01 8.21701527e-01 8.97530973e-01\n",
      " 2.59403676e-01 9.24790561e-01 1.98523939e-01 6.49172580e-03\n",
      " 4.24673595e-03 3.77777040e-01 6.52478814e-01 6.44642413e-02\n",
      " 4.17840891e-02 1.11406930e-02 1.00783698e-01 4.01616842e-02\n",
      " 5.85720122e-01 9.55886781e-01 8.99515767e-03 5.94630957e-01\n",
      " 9.98913527e-01 9.97071028e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 9 [0/43 (0%)]\tTrain Loss: 0.014920\n",
      "Train Epoch: 9 [10/43 (23%)]\tTrain Loss: 0.004668\n",
      "Train Epoch: 9 [20/43 (47%)]\tTrain Loss: 0.009612\n",
      "Train Epoch: 9 [30/43 (70%)]\tTrain Loss: 0.017788\n",
      "Train Epoch: 9 [40/43 (93%)]\tTrain Loss: 0.028961\n",
      "\n",
      "Train set: Average loss: 0.0128, Accuracy: 405/425 (95%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.42170449e-02 4.10881452e-02 7.50654191e-02 6.22514822e-02\n",
      " 3.05443024e-03 1.50317587e-02 7.32986704e-02 1.03997335e-01\n",
      " 8.81657377e-02 5.68956435e-01 7.93432295e-01 7.70615265e-02\n",
      " 7.44745076e-01 1.52824037e-02 2.41659284e-02 7.53246946e-03\n",
      " 2.09965510e-03 8.45881477e-02 6.26485050e-03 9.26246718e-02\n",
      " 9.91211161e-02 8.91062379e-01 2.23673627e-01 9.94203985e-01\n",
      " 7.50807643e-01 1.27684385e-01 6.79943323e-01 2.22738355e-01\n",
      " 1.27905915e-02 7.15299509e-03 7.86935817e-03 8.64700377e-02\n",
      " 1.37644365e-01 3.49708018e-04 9.68926761e-04 8.80302954e-03\n",
      " 1.89644331e-03 6.77787885e-02 9.13613364e-02 2.78364215e-02\n",
      " 1.83283761e-02 4.55407705e-03 2.27236319e-02 3.86031941e-02\n",
      " 7.01197565e-01 2.07536574e-02 7.18534812e-02 1.09409586e-01\n",
      " 1.76876694e-01 3.40688601e-02 2.75377542e-01 7.30703527e-04\n",
      " 4.13263962e-03 5.12856874e-04 1.37905646e-02 4.56202170e-03\n",
      " 6.73790753e-01 2.66906311e-04 1.41689554e-02 6.46632048e-04\n",
      " 9.98937309e-01 9.98228014e-01 9.99589503e-01 9.98666525e-01\n",
      " 5.19348830e-02 6.27377331e-01 1.99869916e-01 9.99997854e-01\n",
      " 9.93517876e-01 9.45797503e-01 1.93050820e-02 2.21987907e-02\n",
      " 6.02693617e-01 1.07807435e-01 5.38268924e-01 8.52897525e-01\n",
      " 9.34759676e-01 4.87724870e-01 9.56685960e-01 9.93774295e-01\n",
      " 9.84512091e-01 9.14977431e-01 9.98169065e-01 7.64770746e-01\n",
      " 4.94946651e-02 9.79279160e-01 9.85912025e-01 9.36371028e-01\n",
      " 1.83994193e-02 7.04005361e-01 9.13059473e-01 4.72352020e-02\n",
      " 2.11252552e-02 9.91984665e-01 2.34633490e-01 3.20820898e-01\n",
      " 3.31893593e-01 9.97584343e-01 9.81435418e-01 9.67398584e-01\n",
      " 6.38938069e-01 9.92968500e-01 7.08803892e-01 8.15166831e-02\n",
      " 3.17813493e-02 8.31986606e-01 8.30070257e-01 5.17127454e-01\n",
      " 5.14876962e-01 2.68556438e-02 7.35639453e-01 1.17809825e-01\n",
      " 8.44693840e-01 9.99752104e-01 1.38610601e-02 8.44952285e-01\n",
      " 9.99943614e-01 9.99915600e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 10 [0/43 (0%)]\tTrain Loss: 0.005225\n",
      "Train Epoch: 10 [10/43 (23%)]\tTrain Loss: 0.011901\n",
      "Train Epoch: 10 [20/43 (47%)]\tTrain Loss: 0.010383\n",
      "Train Epoch: 10 [30/43 (70%)]\tTrain Loss: 0.006166\n",
      "Train Epoch: 10 [40/43 (93%)]\tTrain Loss: 0.001850\n",
      "\n",
      "Train set: Average loss: 0.0139, Accuracy: 405/425 (95%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.28123630e-02 2.28172392e-02 5.92285804e-02 1.91305373e-02\n",
      " 4.13889589e-04 4.64785984e-03 5.31050712e-02 2.76163481e-02\n",
      " 2.76667345e-02 3.58640581e-01 6.88820958e-01 4.01372053e-02\n",
      " 5.10443926e-01 2.06536893e-03 2.01072777e-03 5.23931230e-04\n",
      " 3.09262512e-04 6.30742908e-02 3.06077907e-03 6.01385953e-03\n",
      " 2.29680371e-02 9.00492787e-01 1.25834748e-01 9.95984674e-01\n",
      " 6.91704452e-01 8.41553137e-02 3.82270128e-01 1.64909884e-02\n",
      " 7.65252975e-04 1.60349824e-03 3.11944634e-03 2.86365040e-02\n",
      " 3.95864137e-02 5.00404894e-05 5.34491031e-04 5.26034448e-04\n",
      " 3.40905128e-04 1.71861053e-02 2.98114643e-02 2.95699132e-03\n",
      " 3.56411398e-03 1.41935097e-03 1.44682778e-02 1.29306456e-02\n",
      " 2.55251765e-01 1.79265942e-02 5.83298206e-02 2.33443435e-02\n",
      " 1.88320696e-01 2.25228220e-02 3.81286770e-01 1.69776380e-04\n",
      " 1.78235245e-03 1.32996400e-04 2.47775833e-03 8.87178292e-04\n",
      " 6.37545049e-01 8.26860196e-05 6.36266870e-03 1.37376643e-04\n",
      " 9.99840975e-01 9.98520195e-01 9.99877810e-01 9.97406662e-01\n",
      " 3.76828499e-02 1.36370257e-01 4.56450656e-02 9.99999642e-01\n",
      " 9.99268472e-01 2.61298209e-01 2.99864933e-02 1.92725789e-02\n",
      " 1.45156413e-01 1.51773551e-02 1.82041049e-01 9.78539586e-01\n",
      " 9.83990908e-01 7.90873647e-01 9.69670057e-01 9.82532501e-01\n",
      " 9.25042272e-01 9.51348305e-01 9.98952508e-01 8.98574173e-01\n",
      " 4.95517924e-02 9.67915177e-01 9.92262363e-01 9.84927654e-01\n",
      " 5.10537159e-03 2.80607849e-01 7.54293323e-01 2.88729314e-02\n",
      " 1.64170936e-02 9.94923174e-01 1.56062201e-01 2.38406613e-01\n",
      " 2.45709404e-01 9.98030484e-01 9.68026936e-01 8.15155268e-01\n",
      " 5.24966359e-01 9.40227151e-01 1.62749112e-01 2.29413435e-02\n",
      " 8.09394103e-03 3.63292515e-01 4.74857777e-01 1.78521886e-01\n",
      " 1.06482878e-01 8.41951929e-03 1.47753254e-01 5.86422943e-02\n",
      " 7.37640798e-01 9.97989178e-01 5.07566659e-03 2.18925387e-01\n",
      " 9.99989390e-01 9.99819934e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 32 TN= 54 FN= 26 FP= 6\n",
      "TP+FP 38\n",
      "precision 0.8421052631578947\n",
      "recall 0.5517241379310345\n",
      "F1 0.6666666666666666\n",
      "acc 0.7288135593220338\n",
      "AUCp 0.7258620689655173\n",
      "AUC 0.818103448275862\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model_backup/efficientNet-b0.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-164501b81b59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;31m#         if epoch == total_epoch:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_backup/{}.pt\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mvote_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_backup/efficientNet-b0.pt'"
     ]
    }
   ],
   "source": [
    "bs = 10\n",
    "votenum = 10\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "r_list = []\n",
    "p_list = []\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "# TP = 0\n",
    "# TN = 0\n",
    "# FN = 0\n",
    "# FP = 0\n",
    "vote_pred = np.zeros(valset.__len__())\n",
    "vote_score = np.zeros(valset.__len__())\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "#scheduler = StepLR(optimizer, step_size=1)\n",
    "\n",
    "total_epoch = 3000\n",
    "for epoch in range(1, total_epoch+1):\n",
    "    train(optimizer, epoch)\n",
    "    \n",
    "    targetlist, scorelist, predlist = val(epoch)\n",
    "    print('target',targetlist)\n",
    "    print('score',scorelist)\n",
    "    print('predict',predlist)\n",
    "    vote_pred = vote_pred + predlist \n",
    "    vote_score = vote_score + scorelist \n",
    "\n",
    "    if epoch % votenum == 0:\n",
    "        \n",
    "        # major vote\n",
    "        vote_pred[vote_pred <= (votenum/2)] = 0\n",
    "        vote_pred[vote_pred > (votenum/2)] = 1\n",
    "        vote_score = vote_score/votenum\n",
    "        \n",
    "        print('vote_pred', vote_pred)\n",
    "        print('targetlist', targetlist)\n",
    "        TP = ((vote_pred == 1) & (targetlist == 1)).sum()\n",
    "        TN = ((vote_pred == 0) & (targetlist == 0)).sum()\n",
    "        FN = ((vote_pred == 0) & (targetlist == 1)).sum()\n",
    "        FP = ((vote_pred == 1) & (targetlist == 0)).sum()\n",
    "        \n",
    "        \n",
    "        print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "        print('TP+FP',TP+FP)\n",
    "        p = TP / (TP + FP)\n",
    "        print('precision',p)\n",
    "        p = TP / (TP + FP)\n",
    "        r = TP / (TP + FN)\n",
    "        print('recall',r)\n",
    "        F1 = 2 * r * p / (r + p)\n",
    "        acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "        print('F1',F1)\n",
    "        print('acc',acc)\n",
    "        AUC = roc_auc_score(targetlist, vote_score)\n",
    "        print('AUCp', roc_auc_score(targetlist, vote_pred))\n",
    "        print('AUC', AUC)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         if epoch == total_epoch:\n",
    "        torch.save(model.state_dict(), \"model_backup/{}.pt\".format(modelname))  \n",
    "        \n",
    "        vote_pred = np.zeros(valset.__len__())\n",
    "        vote_score = np.zeros(valset.__len__())\n",
    "        print('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\n",
    "\n",
    "        f = open('model_result/{}.txt'.format(modelname), 'a+')\n",
    "        f.write('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP= 62 TN= 76 FN= 43 FP= 22\n",
      "TP+FP 84\n",
      "precision 0.7380952380952381\n",
      "recall 0.5904761904761905\n",
      "F1 0.656084656084656\n",
      "acc 0.6798029556650246\n",
      "AUC 0.7936831875607385\n",
      "TP= 62 TN= 76 FN= 43 FP= 22\n",
      "TP+FP 84\n",
      "precision 0.7380952380952381\n",
      "recall 0.5904761904761905\n",
      "F1 0.656084656084656\n",
      "acc 0.6798029556650246\n",
      "AUC 0.7936831875607385\n",
      "TP= 62 TN= 76 FN= 43 FP= 22\n",
      "TP+FP 84\n",
      "precision 0.7380952380952381\n",
      "recall 0.5904761904761905\n",
      "F1 0.656084656084656\n",
      "acc 0.6798029556650246\n",
      "AUC 0.7936831875607385\n",
      "TP= 62 TN= 76 FN= 43 FP= 22\n",
      "TP+FP 84\n",
      "precision 0.7380952380952381\n",
      "recall 0.5904761904761905\n",
      "F1 0.656084656084656\n",
      "acc 0.6798029556650246\n",
      "AUC 0.7936831875607385\n",
      "TP= 62 TN= 76 FN= 43 FP= 22\n",
      "TP+FP 84\n",
      "precision 0.7380952380952381\n",
      "recall 0.5904761904761905\n",
      "F1 0.656084656084656\n",
      "acc 0.6798029556650246\n",
      "AUC 0.7936831875607385\n",
      "TP= 62 TN= 76 FN= 43 FP= 22\n",
      "TP+FP 84\n",
      "precision 0.7380952380952381\n",
      "recall 0.5904761904761905\n",
      "F1 0.656084656084656\n",
      "acc 0.6798029556650246\n",
      "AUC 0.7936831875607385\n",
      "TP= 62 TN= 76 FN= 43 FP= 22\n",
      "TP+FP 84\n",
      "precision 0.7380952380952381\n",
      "recall 0.5904761904761905\n",
      "F1 0.656084656084656\n",
      "acc 0.6798029556650246\n",
      "AUC 0.7936831875607385\n",
      "TP= 62 TN= 76 FN= 43 FP= 22\n",
      "TP+FP 84\n",
      "precision 0.7380952380952381\n",
      "recall 0.5904761904761905\n",
      "F1 0.656084656084656\n",
      "acc 0.6798029556650246\n",
      "AUC 0.7936831875607385\n",
      "TP= 62 TN= 76 FN= 43 FP= 22\n",
      "TP+FP 84\n",
      "precision 0.7380952380952381\n",
      "recall 0.5904761904761905\n",
      "F1 0.656084656084656\n",
      "acc 0.6798029556650246\n",
      "AUC 0.7936831875607385\n",
      "TP= 62 TN= 76 FN= 43 FP= 22\n",
      "TP+FP 84\n",
      "precision 0.7380952380952381\n",
      "recall 0.5904761904761905\n",
      "F1 0.656084656084656\n",
      "acc 0.6798029556650246\n",
      "AUC 0.7936831875607385\n",
      "TP= 62 TN= 76 FN= 43 FP= 22\n",
      "TP+FP 84\n",
      "precision 0.7380952380952381\n",
      "recall 0.5904761904761905\n",
      "F1 0.656084656084656\n",
      "acc 0.6798029556650246\n",
      "AUC 0.7936831875607385\n",
      "vote_pred [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " The epoch is 10, average recall: 0.5905, average precision: 0.7381,average F1: 0.6561, average accuracy: 0.6798, average AUC: 0.7937\n"
     ]
    }
   ],
   "source": [
    "bs = 10\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "r_list = []\n",
    "p_list = []\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "# TP = 0\n",
    "# TN = 0\n",
    "# FN = 0\n",
    "# FP = 0\n",
    "vote_pred = np.zeros(testset.__len__())\n",
    "vote_score = np.zeros(testset.__len__())\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "scheduler = StepLR(optimizer, step_size=1)\n",
    "\n",
    "total_epoch = 10\n",
    "for epoch in range(1, total_epoch+1):\n",
    "    \n",
    "    targetlist, scorelist, predlist = test(epoch)\n",
    "#     print('target',targetlist)\n",
    "#     print('score',scorelist)\n",
    "#     print('predict',predlist)\n",
    "    vote_pred = vote_pred + predlist \n",
    "    vote_score = vote_score + scorelist \n",
    "    \n",
    "    TP = ((predlist == 1) & (targetlist == 1)).sum()\n",
    "    TN = ((predlist == 0) & (targetlist == 0)).sum()\n",
    "    FN = ((predlist == 0) & (targetlist == 1)).sum()\n",
    "    FP = ((predlist == 1) & (targetlist == 0)).sum()\n",
    "\n",
    "    print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "    print('TP+FP',TP+FP)\n",
    "    p = TP / (TP + FP)\n",
    "    print('precision',p)\n",
    "    p = TP / (TP + FP)\n",
    "    r = TP / (TP + FN)\n",
    "    print('recall',r)\n",
    "    F1 = 2 * r * p / (r + p)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print('F1',F1)\n",
    "    print('acc',acc)\n",
    "    AUC = roc_auc_score(targetlist, vote_score)\n",
    "    print('AUC', AUC)\n",
    "\n",
    "    if epoch % votenum == 0:\n",
    "        \n",
    "        # major vote\n",
    "        vote_pred[vote_pred <= (votenum/2)] = 0\n",
    "        vote_pred[vote_pred > (votenum/2)] = 1\n",
    "        \n",
    "#         print('vote_pred', vote_pred)\n",
    "#         print('targetlist', targetlist)\n",
    "        TP = ((vote_pred == 1) & (targetlist == 1)).sum()\n",
    "        TN = ((vote_pred == 0) & (targetlist == 0)).sum()\n",
    "        FN = ((vote_pred == 0) & (targetlist == 1)).sum()\n",
    "        FP = ((vote_pred == 1) & (targetlist == 0)).sum()\n",
    "        \n",
    "        print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "        print('TP+FP',TP+FP)\n",
    "        p = TP / (TP + FP)\n",
    "        print('precision',p)\n",
    "        p = TP / (TP + FP)\n",
    "        r = TP / (TP + FN)\n",
    "        print('recall',r)\n",
    "        F1 = 2 * r * p / (r + p)\n",
    "        acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "        print('F1',F1)\n",
    "        print('acc',acc)\n",
    "        AUC = roc_auc_score(targetlist, vote_score)\n",
    "        print('AUC', AUC)\n",
    "        \n",
    "        \n",
    "#         f = open('model_result/{modelname}.txt', 'a+')\n",
    "#         f.write('precision, recall, F1, acc= \\n')\n",
    "#         f.writelines(str(p))\n",
    "#         f.writelines('\\n')\n",
    "#         f.writelines(str(r))\n",
    "#         f.writelines('\\n')\n",
    "#         f.writelines(str(F1))\n",
    "#         f.writelines('\\n')\n",
    "#         f.writelines(str(acc))\n",
    "#         f.writelines('\\n')\n",
    "#         f.close()\n",
    "        \n",
    "        \n",
    "        vote_pred = np.zeros((1,testset.__len__()))\n",
    "        vote_score = np.zeros(testset.__len__())\n",
    "        print('vote_pred',vote_pred)\n",
    "        print('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\n",
    "\n",
    "        #f = open(f'model_result/test_{modelname}.txt', 'a+')\n",
    "        #f.write('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        #epoch, r, p, F1, acc, AUC))\n",
    "        #f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(vote_score)\n",
    "print(vote_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
